{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#Assignment No 2c\n",
    "\n",
    "Text Classification (Sentiment Analysis) Using Naive Bayes Rule \n",
    "==============\n",
    "*Sibt ul Hussain*\n",
    "\n",
    "##Goal\n",
    "\n",
    "Your goal in this part of assigment is to implement a Naive Bayes Multinomial classifier using  bag of words model for the classification of text (movie reviews) into different categories..\n",
    "\n",
    "**Note** Please note that you are allowed to use only those libraries which we have discussed in the class, i.e. numpy, scipy, pandas.\n",
    "\n",
    "Once you have build and test the model on the provided dataset. You will use the learned techniques to compete in a [Kaggle](https://www.kaggle.com/c/word2vec-nlp-tutorial) competition and report your final score and leaderboard ranking to get full credit.\n",
    "\n",
    "For final submission attach the screen-shot of the leader-board with your score.\n",
    "\n",
    "##Submission Instructions\n",
    "You are required to submit the original notebook file on the Slate (with .ipynb extension), with complete set of outputs. Students failing to do so will get zero marks. \n",
    "\n",
    "*Please read each step carefully and understand it fully before proceeding with code writing*\n",
    "\n",
    "##Plagiarism\n",
    "Any form of plagiarism will not be tolerated and result in 0 marks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import scipy.stats\n",
    "from collections import defaultdict\n",
    "plt.style.use('ggplot')\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Task Complete the following function...\n",
    "def parse_string(string): # Parse a read string into respective tokens\n",
    "    \"\"\"\"\n",
    "        Parse the input string and tokenize it into words: (You can use regular expressions as well)\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        string: string to be parsed...\n",
    "\n",
    "        \n",
    "        Returns:\n",
    "        ---------\n",
    "        list of tokens extracted from the string...\n",
    "    \"\"\"\n",
    "    \n",
    "    # write your code here...\n",
    "    \n",
    " \n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_file(filename): # Parse a given file\n",
    "    \"\"\"\"\n",
    "        Parse the input file and tokenize it :\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        filename: name of text file to be read\n",
    "   \n",
    "        \n",
    "        Returns:\n",
    "        ---------\n",
    "        read file as raw string (with \\n, \\t, \\r, etc included)\n",
    "    \"\"\"\n",
    "    \n",
    "  \n",
    "    \n",
    "    with open(filename,'r') as rfile:\n",
    "        rstring=rfile.read()\n",
    "    \n",
    "    return rstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def files_to_strings(X):\n",
    "    \n",
    "    \"\"\"\n",
    "        Read an array of files where each file content is read in a string...\n",
    "        Input:\n",
    "        -------\n",
    "        X an array of file names\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        X as a numpy array with each row containing a read string from the file...\n",
    "    \"\"\"\n",
    "    rX=np.zeros((X.shape[0],1),dtype=object)\n",
    "    for ei in range(X.shape[0]):\n",
    "        rX[ei,0]=parse_file(X[ei][0])\n",
    "        \n",
    "    return rX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Hint, you can use python dictionary or default dict for counting the words\n",
    "# or counter class from collections \n",
    "\n",
    "#TODO Complete this class for running the complete classifier... \n",
    "\n",
    "#You might need to define auxiliary classes for the complete algorithm..\n",
    "\n",
    "#Task Complete the following class...\n",
    "class NaiveBayes:\n",
    "    ''' Implements the Naive Bayes For Text Classification... '''\n",
    "    def __init__(self, classes):\n",
    "        self.classes=classes\n",
    "        \n",
    "    def train(self, X, Y):\n",
    "        ''' Train the multiclass (or Binary) Bayes Rule using the given \n",
    "            X [m x d] data matrix and Y labels matrix\n",
    "            \n",
    "            Input:\n",
    "            ------\n",
    "            X: [m x d] a data matrix of m d-dimensional examples.\n",
    "            Y: [m x 1] a label vector.\n",
    "            \n",
    "            Returns:\n",
    "            -----------\n",
    "            Nothing\n",
    "            '''\n",
    "        \n",
    "            ## now go and train a model for each class...\n",
    "        \n",
    "    def test(self, X):\n",
    "        \n",
    "        ''' Test the trained classifiers on the given set of examples \n",
    "        \n",
    "                   \n",
    "            Input:\n",
    "            ------\n",
    "            X: [m x d] a data matrix of m d-dimensional test examples.\n",
    "           \n",
    "            Returns:\n",
    "            -----------\n",
    "                pclass: the predicted class for each example, i.e. to which it belongs\n",
    "        '''\n",
    "        \n",
    "        nexamples, nfeatures=X.shape\n",
    "        pclasses=[0]*nexamples\n",
    "        \n",
    "        # your code go here...\n",
    "        \n",
    "        return np.array(pclasses)\n",
    "    def addExample(self, x, y):\n",
    "        '''\n",
    "            Add example to corresponding class model ...\n",
    "            \n",
    "            Input\n",
    "            ---------\n",
    "            x: example (list of words)\n",
    "            y: label...\n",
    "        '''\n",
    "         \n",
    "    def predict(self, x):\n",
    "        '''\n",
    "            Predict the label of given input example...\n",
    "            \n",
    "            Input\n",
    "            ---------\n",
    "            x: example (list of words)\n",
    "            \n",
    "        '''\n",
    "        \n",
    "        \n",
    "        return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tools as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tdir='./data/sentiment/data/imdb1/' # training dir...\n",
    "#load data, get list of files for each class...\n",
    "posfiles=t.get_files(tdir+'/pos','*',withpath=True)\n",
    "negfiles=t.get_files(tdir+'/neg','*',withpath=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data Dimensions = (2000, 1)  Training labels dimensions= (2000,)\n"
     ]
    }
   ],
   "source": [
    "#generate training and testing data...\n",
    "plabels=['pos']*len(posfiles)\n",
    "nlabels=['neg']*len(posfiles)\n",
    "labels=np.concatenate((plabels,nlabels)) # concatenate the +ve and -ve labels\n",
    "tX=np.concatenate((posfiles,negfiles)).reshape((len(posfiles)+len(negfiles),1))\n",
    "print \"Training data Dimensions =\", tX.shape,\" Training labels dimensions=\", labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=file_to_strings(tX) # read files and convert each file into set of strings and return an numpy array\n",
    "\n",
    "#Split the data into two halves training and test set...\n",
    "traindata,trainlabels,testdata,testlabels=t.split_data(X,labels)\n",
    "#Find the classes to train\n",
    "classes=np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] training a classifier for following classes neg, pos\n",
      "[Info] Accuracy = 0.798333333333\n"
     ]
    }
   ],
   "source": [
    "#Now build a Naive Bayes classifier and test it...\n",
    "print '[Info] training a classifier for following classes {}, {}'.format(classes[0],classes[1])\n",
    "nb=NaiveBayes(classes)\n",
    "nb.train(traindata,trainlabels)\n",
    "pclasses=nb.test(testdata)\n",
    "acc=np.sum(pclasses==testlabels)/float(testlabels.shape[0])\n",
    "print \"[Info] Accuracy = {}\".format(acc)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Cross Validation\n",
    "\n",
    "Now lets throw our methods to winds of different folds and measure their accuracy..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating CV data for 2 classes\n",
      "(1800, 1) (200, 1)\n",
      "(1800, 1) (200, 1)\n",
      "(1800, 1) (200, 1)\n",
      "(1800, 1) (200, 1)\n",
      "(1800, 1) (200, 1)\n",
      "(1800, 1) (200, 1)\n",
      "(1800, 1) (200, 1)\n",
      "(1800, 1) (200, 1)\n",
      "(1800, 1) (200, 1)\n",
      "(1800, 1) (200, 1)\n"
     ]
    }
   ],
   "source": [
    "#Now lets generate n-fold training and testing data...\n",
    "\n",
    "nfolds=10\n",
    "folds=t.generate_folds(X,labels,nfolds) # generate folds for \n",
    "for k in arange(len(folds)):\n",
    "    print folds[k][0].shape, folds[k][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Fold 1 Accuracy = 0.835\n",
      "[Info] Fold 2 Accuracy = 0.805\n",
      "[Info] Fold 3 Accuracy = 0.8\n",
      "[Info] Fold 4 Accuracy = 0.775\n",
      "[Info] Fold 5 Accuracy = 0.825\n",
      "[Info] Fold 6 Accuracy = 0.795\n",
      "[Info] Fold 7 Accuracy = 0.84\n",
      "[Info] Fold 8 Accuracy = 0.805\n",
      "[Info] Fold 9 Accuracy = 0.85\n",
      "[Info] Fold 10 Accuracy = 0.8\n",
      "[0.83499999999999996, 0.80500000000000005, 0.80000000000000004, 0.77500000000000002, 0.82499999999999996, 0.79500000000000004, 0.83999999999999997, 0.80500000000000005, 0.84999999999999998, 0.80000000000000004]\n",
      "[Info] Mean Accuracy = 0.813\n"
     ]
    }
   ],
   "source": [
    "totacc=[]\n",
    "#train a classifier for each fold...\n",
    "classes=np.unique(labels)\n",
    "\n",
    "for k in range(nfolds):\n",
    "    nb=NaiveBayes(classes)\n",
    "    \n",
    "    traindata=folds[k][0]\n",
    "    trainlabels=folds[k][1]\n",
    "    \n",
    "    #Lets first train the classifier\n",
    "    nb.train(traindata,trainlabels)\n",
    "    \n",
    "    testdata=folds[k][2]\n",
    "    testlabels=folds[k][3]\n",
    "    \n",
    "    #Lets test the classifier\n",
    "    pclasses= nb.test(testdata)\n",
    "    \n",
    "    acc=np.sum(pclasses==testlabels)/float(testlabels.shape[0])\n",
    "    print \"[Info] Fold {} Accuracy = {}\".format(k+1, acc)    \n",
    "    \n",
    "    totacc.append(acc)\n",
    "\n",
    "print totacc\n",
    "print '[Info] Mean Accuracy =', np.mean(totacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Excellent, now its time to dive into deep waters of Kaggle.\n",
    "\n",
    "\n",
    "You will be needed to create an account on the Kaggle and download the data for the competition [\"Bag of words meets bags of popcorn\"](https://www.kaggle.com/c/word2vec-nlp-tutorial/data).  Note that you will be only downloading the \"labeledTrainData.tsv\" and \"labeledTestData.tsv\".\n",
    "\n",
    "\n",
    "\"labeledTrainData.tsv\" will be used for training your model and thus have prespecified labels for each example review. \"labeledTestData.tsv\" will be used for testing your model and thus don't have prespecified labels for each example. You will predicting the label for each review and then uploading your result to Kaggle server which will be evaluating your model and will give score to your entry. You will report this score during your assignment submission.\n",
    "\n",
    "**[Caution]** Please note that Kaggle limits maximum number of evaluations per 24 hours to 5 to reduce the overfitting on the test set, so be careful and throughly test your model before submitting your entry to Kaggle server. \n",
    "\n",
    "Read the instructions on the Competition Page. Note you are not allowed to use any of the library except what we have learned during class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read the data-set\n",
    "train=pd.read_csv('/tmp/labeledTrainData.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td> 25000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>     0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>     0.50001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>     0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>     0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>     0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>     1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>     1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment\n",
       "count  25000.00000\n",
       "mean       0.50000\n",
       "std        0.50001\n",
       "min        0.00000\n",
       "25%        0.00000\n",
       "50%        0.50000\n",
       "75%        1.00000\n",
       "max        1.00000"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 5814_8</td>\n",
       "      <td> 1</td>\n",
       "      <td> With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 2381_9</td>\n",
       "      <td> 1</td>\n",
       "      <td> \\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 7759_3</td>\n",
       "      <td> 0</td>\n",
       "      <td> The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 3630_4</td>\n",
       "      <td> 0</td>\n",
       "      <td> It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 9495_8</td>\n",
       "      <td> 1</td>\n",
       "      <td> Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "Yt=train['sentiment']\n",
    "Xt=train['review']\n",
    "Xt=np.array(Xt)\n",
    "Yt=np.array(Yt)\n",
    "\n",
    "print Xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read test set...\n",
    "test=pd.read_csv('/tmp/testData.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 12311_10</td>\n",
       "      <td> Naturally in a film who's main themes are of m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>   8348_2</td>\n",
       "      <td> This movie is a disaster within a disaster fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>   5828_4</td>\n",
       "      <td> All in all, this is a movie for kids. We saw i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>   7186_2</td>\n",
       "      <td> Afraid of the Dark left me with the impression...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>  12128_7</td>\n",
       "      <td> A very accurate depiction of small time mob li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                             review\n",
       "0  12311_10  Naturally in a film who's main themes are of m...\n",
       "1    8348_2  This movie is a disaster within a disaster fil...\n",
       "2    5828_4  All in all, this is a movie for kids. We saw i...\n",
       "3    7186_2  Afraid of the Dark left me with the impression...\n",
       "4   12128_7  A very accurate depiction of small time mob li..."
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Training Time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's split the training data into two halves and test our accuracy...\n",
    "traindata,trainlabels,testdata,testlabels=t.split_data(Xt.reshape((Xt.shape[0],1)),Yt)\n",
    "classes=np.unique(trainlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] training a classifier for following classes 0, 1\n",
      "[Info] Accuracy = 0.841733333333\n"
     ]
    }
   ],
   "source": [
    "# Now lets go and train the model and see its performance...\n",
    "print '[Info] training a classifier for following classes {}, {}'.format(classes[0],classes[1])\n",
    "nb=NaiveBayes(classes)\n",
    "nb.train(traindata,trainlabels)\n",
    "pclasses=nb.test(testdata)\n",
    "acc=np.sum(pclasses==testlabels)/float(testlabels.shape[0])\n",
    "print \"[Info] Accuracy = {}\".format(acc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-Validation Time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating CV data for 2 classes\n",
      "(22500, 1) (2500, 1)\n",
      "(22500, 1) (2500, 1)\n",
      "(22500, 1) (2500, 1)\n",
      "(22500, 1) (2500, 1)\n",
      "(22500, 1) (2500, 1)\n",
      "(22500, 1) (2500, 1)\n",
      "(22500, 1) (2500, 1)\n",
      "(22500, 1) (2500, 1)\n",
      "(22500, 1) (2500, 1)\n",
      "(22500, 1) (2500, 1)\n"
     ]
    }
   ],
   "source": [
    "#Split the training data into 10 folds and test classifiers performance...\n",
    "\n",
    "nfolds=10\n",
    "folds=t.generate_folds(Xt.reshape((Xt.shape[0],1)),Yt,nfolds) # generate folds for \n",
    "for k in arange(len(folds)):\n",
    "    print folds[k][0].shape, folds[k][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# As it takes time, so becareful it can cause your machine into red hot oven\n",
    "totacc=[]\n",
    "classes=np.unique(Yt)\n",
    "\n",
    "for k in range(nfolds):\n",
    "    nb=NaiveBayes(classes)\n",
    "    \n",
    "    traindata=folds[k][0]\n",
    "    trainlabels=folds[k][1]\n",
    "    \n",
    "    #Lets first train the classifier\n",
    "    nb.train(traindata,trainlabels)\n",
    "    \n",
    "    testdata=folds[k][2]\n",
    "    testlabels=folds[k][3]\n",
    "    \n",
    "    #Lets test the classifier\n",
    "    pclasses= nb.test(testdata)\n",
    "    \n",
    "    acc=np.sum(pclasses==testlabels)/float(testlabels.shape[0])\n",
    "    print \"[Info] Fold {} Accuracy = {}\".format(k+1, acc)    \n",
    "    \n",
    "    totacc.append(acc)\n",
    "\n",
    "print totacc\n",
    "print '[Info] Mean Accuracy =', np.mean(totacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's train on the complete dataset and test on the provided test set..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a Classifier on Full training set with classes = [0 1]\n"
     ]
    }
   ],
   "source": [
    "classes= np.unique(Yt)\n",
    "print 'Training a Classifier on Full training set with classes =', classes\n",
    "nb=NaiveBayes(classes)\n",
    "nb.train(Xt.reshape(Xt.shape[0],1),Yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get the test data...\n",
    "Xtest=test['review']\n",
    "Xtest=np.array(Xtest.reshape((Xtest.shape[0],1)))\n",
    "#test the classifier on the provided test set...\n",
    "pclasses=nb.test(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write the result in the kaggle's required format\n",
    "output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":pclasses} )\n",
    "\n",
    "# Use pandas to write the comma-separated output file\n",
    "output.to_csv( \"/tmp/Naive_bays_Bag_of_Words_model.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to Upload the prediction to Kaggle...\n",
    "\n",
    "Now upload the result on the Kaggle and see your ranking and score. Using this simple method you can have an accuracy of around 0.80960."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Improvement by Excluding Stop Words...\n",
    "\n",
    "You can improve your score further by excluding the commonly occuring words (also known as stop words) in the English language.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['secondly', 'all', 'consider', 'whoever', 'four', 'edu', 'go', 'causes', 'seemed', 'rd', 'certainly', 'vs', 'to', 'asking', 'th', 'under', 'sorry', \"a's\", 'sent', 'far', 'every', 'yourselves', \"we'll\", 'went', 'did', 'forth', \"they've\", 'try', 'p', \"it'll\", \"i'll\", 'says', \"you'd\", 'yourself', 'likely', 'further', 'quite', 'even', 'what', 'appear', 'brief', 'goes', 'sup', 'new', 'ever', \"c'mon\", 'whose', 'respectively', 'never', 'here', 'let', 'others', \"hadn't\", 'along', \"aren't\", 'k', 'allows', \"i'd\", 'howbeit', 'usually', 'whereupon', \"i'm\", 'changes', 'thats', 'hither', 'via', 'followed', 'merely', 'while', 'viz', 'everybody', 'use', 'from', 'would', 'contains', 'two', 'next', 'few', 'therefore', 'taken', 'themselves', 'thru', 'tell', 'more', 'knows', 'becomes', 'hereby', 'herein', \"ain't\", 'particular', 'known', 'must', 'me', 'none', 'f', 'this', 'oh', 'anywhere', 'nine', 'can', 'theirs', 'following', 'my', 'example', 'indicated', \"didn't\", 'indicates', 'something', 'want', 'needs', 'rather', 'meanwhile', 'how', 'instead', 'okay', 'tried', 'may', 'after', 'different', 'hereupon', 'such', 'a', 'third', 'whenever', 'maybe', 'appreciate', 'q', 'ones', 'so', 'specifying', 'allow', 'keeps', \"that's\", 'six', 'help', \"don't\", 'indeed', 'over', 'mainly', 'soon', 'course', 'through', 'looks', 'still', 'its', 'before', 'thank', \"he's\", 'selves', 'inward', 'actually', 'better', 'whether', 'willing', 'thanx', 'ours', 'might', \"haven't\", 'then', 'non', 'someone', 'somebody', 'thereby', \"you've\", 'they', 'not', 'now', 'nor', 'several', 'hereafter', 'always', 'reasonably', 'whither', 'l', 'each', 'entirely', \"isn't\", 'mean', 'everyone', 'doing', 'eg', 'ex', 'our', 'beyond', 'out', 'them', 'furthermore', 'since', 'looking', 're', 'seriously', \"shouldn't\", \"they'll\", 'got', 'cause', 'thereupon', \"you're\", 'given', 'like', 'que', 'besides', 'x', 'ask', 'anyhow', 'g', 'could', 'tries', 'keep', 'w', 'ltd', 'hence', 'onto', 'think', 'first', 'already', 'seeming', 'thereafter', 'one', 'done', 'another', 'awfully', \"doesn't\", 'little', 'their', 'accordingly', 'least', 'name', 'anyone', 'indicate', 'too', 'gives', 'mostly', 'behind', 'nobody', 'took', 'immediate', 'regards', 'somewhat', 'off', 'believe', 'herself', 'than', \"here's\", 'b', 'unfortunately', 'gotten', 'second', 'i', 'r', 'were', 'toward', 'are', 'and', 'beforehand', 'say', 'unlikely', 'have', 'need', 'seen', 'seem', 'saw', 'any', 'relatively', 'zero', 'thoroughly', 'latter', 'that', 'downwards', 'aside', 'thorough', 'also', 'take', 'which', 'exactly', 'unless', 'shall', 'who', \"where's\", 'most', 'eight', 'but', 'nothing', 'why', 'sub', 'especially', 'noone', 'later', 'm', 'yours', \"you'll\", 'definitely', 'normally', 'came', 'saying', 'particularly', 'anyway', 'fifth', 'outside', 'should', 'only', 'going', 'specify', 'do', 'his', 'above', 'get', 'between', 'overall', 'truly', \"they'd\", 'cannot', 'nearly', 'despite', 'during', 'him', 'regarding', 'qv', 'h', 'twice', 'she', 'contain', \"won't\", 'where', 'thanks', 'ignored', 'up', 'namely', 'anyways', 'best', 'wonder', 'said', 'away', 'currently', 'please', 'enough', \"there's\", 'various', 'hopefully', 'probably', 'neither', 'across', 'available', 'we', 'useful', 'however', 'come', 'both', 'c', 'last', 'many', \"wouldn't\", 'thence', 'according', 'against', 'etc', 's', 'became', 'com', \"can't\", 'otherwise', 'among', 'liked', 'co', 'afterwards', 'seems', 'whatever', 'alone', \"couldn't\", 'moreover', 'throughout', 'considering', 'sensible', 'described', \"it's\", 'three', 'been', 'whom', 'much', 'wherein', 'hardly', \"it'd\", 'wants', 'corresponding', 'latterly', 'concerning', 'else', 'hers', 'former', 'those', 'myself', 'novel', 'look', 'these', 'value', 'n', 'will', 'near', 'theres', 'seven', 'whereafter', 'almost', 'wherever', 'is', 'thus', 'it', 'cant', 'itself', 'in', 'ie', 'y', 'if', 'containing', 'perhaps', 'insofar', 'same', 'clearly', 'beside', 'when', 'gets', \"weren't\", 'used', 'see', 'somewhere', 'upon', 'uses', 'kept', 'whereby', 'nevertheless', 'whole', 'well', 'anybody', 'obviously', 'without', 'comes', 'very', 'the', 'self', 'lest', 'just', 'less', 'being', 'able', 'presumably', 'greetings', 'regardless', 'yes', 'yet', 'unto', \"we've\", 'had', 'except', 'has', 'ought', \"t's\", 'around', \"who's\", 'possible', 'five', 'know', 'using', 'apart', 'necessary', 'd', 'follows', 'either', 'become', 'towards', 'therein', 'because', 'old', 'often', 'some', 'somehow', 'sure', 'specified', 'ourselves', 'happens', 'for', 'though', 'per', 'everything', 'does', 'provides', 'tends', 't', 'be', 'nowhere', 'although', 'by', 'on', 'about', 'ok', 'anything', 'getting', 'of', 'v', 'o', 'whence', 'plus', 'consequently', 'or', 'seeing', 'own', 'formerly', 'into', 'within', 'down', 'appropriate', 'right', \"c's\", 'your', 'her', 'there', 'inasmuch', 'inner', 'way', 'was', 'himself', 'elsewhere', \"i've\", 'becoming', 'amongst', 'hi', 'trying', 'with', 'he', \"they're\", \"wasn't\", 'wish', 'j', \"hasn't\", 'us', 'until', 'placed', 'below', 'un', 'z', \"we'd\", 'gone', 'sometimes', 'associated', 'certain', 'am', 'an', 'as', 'sometime', 'at', 'et', 'inc', 'again', 'uucp', 'no', 'whereas', 'nd', 'lately', 'other', 'you', 'really', \"what's\", 'welcome', \"let's\", 'serious', 'e', 'together', 'having', 'u', \"we're\", 'everywhere', 'hello', 'once'])\n"
     ]
    }
   ],
   "source": [
    "#read and create a set of stop \n",
    "stopwords=set(t.read_txt_file('./data/sentiment/data/english.stop'))\n",
    "print stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: Re-Build the model by Excluding Stop Words and Report Performance\n",
    "\n",
    "Now you must re-build the model by excluding these words and again upload your results on Kaggle. \n",
    "\n",
    "Doing this simple trick can further improve your accuracy to 0.81768.\n",
    "\n",
    "For final submission attach the screen-shot of the leader-board with your score\n",
    "\n",
    "Insert ScreenShot of Leader-board Below\n",
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Things You can Try\n",
    "\n",
    "- Use Bigrams instead of uni-grams.\n",
    "- Use of Stemming, etc."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
